#!/usr/bin/env python3
"""
LightOnOCR í†µí•© í´ë¼ì´ì–¸íŠ¸
ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì„ ê¸°ë³¸ìœ¼ë¡œ í•˜ëŠ” OCR ì²˜ë¦¬ ë„êµ¬
"""

import base64
import json
import sys
import time
from pathlib import Path
from typing import Iterator, Optional, Literal, Dict, Any
from enum import Enum
import argparse
import io
import os
import pickle
from dataclasses import dataclass, field
from datetime import datetime
from difflib import SequenceMatcher

import httpx
from PIL import Image
from pdf2image import convert_from_path

try:
    import yaml
except ImportError:
    yaml = None
    print("âš ï¸ PyYAMLì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. YAML ì„¤ì • íŒŒì¼ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì„¤ì¹˜í•˜ì„¸ìš”:")
    print("   uv pip install pyyaml")

# ì„œë²„ ì„¤ì •
SERVER_URL = "http://localhost:8080"
API_ENDPOINT = f"{SERVER_URL}/v1/chat/completions"
HEALTH_ENDPOINT = f"{SERVER_URL}/health"
MODEL_NAME = "LightOnOCR-1B-1025"

# ê¸°ë³¸ ì„¤ì • íŒŒì¼ ê²½ë¡œ
DEFAULT_CONFIG_FILES = [
    Path("ocr_config.yml"),
    Path("ocr_config.yaml"),
    Path(".ocr_config.yml"),
    Path(".ocr_config.yaml"),
    Path.home() / ".config" / "lightonocr" / "config.yml",
]


class SaveMode(Enum):
    """íŒŒì¼ ì €ì¥ ëª¨ë“œ"""
    TOKEN = "token"          # ë§¤ í† í°ë§ˆë‹¤ ì €ì¥ (ê°€ì¥ ë¹ ë¦„)
    WORD = "word"           # ë‹¨ì–´ ë‹¨ìœ„ë¡œ ì €ì¥
    SENTENCE = "sentence"    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì €ì¥
    PARAGRAPH = "paragraph"  # ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ì €ì¥
    LINE = "line"           # ì¤„ ë‹¨ìœ„ë¡œ ì €ì¥


# ì˜ˆì™¸ í´ë˜ìŠ¤ë“¤
class RepetitionError(Exception):
    """ë°˜ë³µ íŒ¨í„´ ê°ì§€ ì‹œ ë°œìƒí•˜ëŠ” ì˜ˆì™¸"""
    pass


class PageTimeoutError(TimeoutError):
    """í˜ì´ì§€ íƒ€ì„ì•„ì›ƒ ì‹œ ë°œìƒí•˜ëŠ” ì˜ˆì™¸"""
    pass


class TokenLimitError(Exception):
    """í† í° ìˆ˜ ì œí•œ ì´ˆê³¼ ì‹œ ë°œìƒí•˜ëŠ” ì˜ˆì™¸"""
    pass


class APIError(Exception):
    """API ìš”ì²­ ì‹¤íŒ¨ ì‹œ ë°œìƒí•˜ëŠ” ì˜ˆì™¸"""
    pass


def load_config_file(config_path: Optional[Path] = None) -> Optional[Dict[str, Any]]:
    """YAML ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if yaml is None:
        return None

    # ì§€ì •ëœ ì„¤ì • íŒŒì¼ ê²½ë¡œê°€ ìˆìœ¼ë©´ ì‚¬ìš©
    if config_path:
        if config_path.exists():
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                    print(f"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ: {config_path}")
                    return config
            except Exception as e:
                print(f"âš ï¸ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
                return None
        else:
            print(f"âŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
            return None

    # ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìœ„ì¹˜ì—ì„œ ì°¾ê¸°
    for default_path in DEFAULT_CONFIG_FILES:
        if default_path.exists():
            try:
                with open(default_path, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                    print(f"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ: {default_path}")
                    return config
            except Exception as e:
                continue

    return None


def create_default_config(config_path: Path) -> bool:
    """ê¸°ë³¸ ì„¤ì • íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    default_config = {
        'server': {
            'url': 'http://localhost:8080',
            'model': 'LightOnOCR-1B-1025',
            'timeout': 120
        },
        'ocr': {
            'streaming': True,
            'save_mode': 'token',
            'save_file': True,
            'quiet': False,
            'show_stats': False
        },
        'pdf': {
            'skip_errors': False,
            'max_retries': 2,
            'page_timeout': 120.0,
            'max_page_tokens': 8000,
            'dpi': 200
        },
        'image': {
            'jpeg_quality': 95,
            'supported_formats': ['.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff']
        },
        'advanced': {
            'repetition_detection': {
                'enabled': True,
                'window_size': 50,
                'threshold': 0.8,
                'max_normal_reps': 5
            },
            'api': {
                'temperature': 0.1,
                'max_tokens': 4096
            }
        },
        'output': {
            'include_headers': True,
            'include_separators': True,
            'include_timing': True
        },
        'debug': {
            'enabled': False,
            'log_api_calls': False
        }
    }

    try:
        # ë””ë ‰í† ë¦¬ ìƒì„±
        config_path.parent.mkdir(parents=True, exist_ok=True)

        if yaml:
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(default_config, f, default_flow_style=False, sort_keys=False, allow_unicode=True)
            print(f"âœ… ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„±: {config_path}")
            return True
        else:
            print("âš ï¸ PyYAMLì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì„¤ì • íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
    except Exception as e:
        print(f"âŒ ì„¤ì • íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
        return False


def merge_config_with_args(config: Dict[str, Any], args: argparse.Namespace) -> argparse.Namespace:
    """YAML ì„¤ì •ê³¼ ëª…ë ¹ì¤„ ì¸ìë¥¼ ë³‘í•©í•©ë‹ˆë‹¤. ëª…ë ¹ì¤„ ì¸ìê°€ ìš°ì„ ìˆœìœ„ë¥¼ ê°€ì§‘ë‹ˆë‹¤."""
    # ì„¤ì • ê°’ì„ argsì— ì ìš© (ëª…ë ¹ì¤„ì—ì„œ ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš°ë§Œ)

    # ì„œë²„ ì„¤ì •
    if 'server' in config:
        if not args.server:
            args.server = config['server'].get('url', SERVER_URL)

    # OCR ì„¤ì •
    if 'ocr' in config:
        ocr = config['ocr']
        # no_streamì€ ë°˜ëŒ€ ë…¼ë¦¬
        if not hasattr(args, 'no_stream') or args.no_stream is False:
            args.no_stream = not ocr.get('streaming', True)

        if not args.save_mode or args.save_mode == SaveMode.TOKEN.value:
            args.save_mode = ocr.get('save_mode', SaveMode.TOKEN.value)

        if not args.quiet:
            args.quiet = ocr.get('quiet', False)

        if not args.stats:
            args.stats = ocr.get('show_stats', False)

        if not args.no_save:
            args.no_save = not ocr.get('save_file', True)

    # PDF ì„¤ì •
    if 'pdf' in config:
        pdf = config['pdf']
        if not args.skip_errors:
            args.skip_errors = pdf.get('skip_errors', False)

        if args.max_retries == 2:  # ê¸°ë³¸ê°’ì¸ ê²½ìš°ë§Œ
            args.max_retries = pdf.get('max_retries', 2)

        if args.page_timeout == 120.0:  # ê¸°ë³¸ê°’ì¸ ê²½ìš°ë§Œ
            args.page_timeout = pdf.get('page_timeout', 120.0)

        if args.max_page_tokens == 8000:  # ê¸°ë³¸ê°’ì¸ ê²½ìš°ë§Œ
            args.max_page_tokens = pdf.get('max_page_tokens', 8000)

    return args


class RepetitionDetector:
    """í† í° ë°˜ë³µ íŒ¨í„´ ê°ì§€ê¸°"""

    def __init__(self,
                 window_size: int = 50,
                 threshold: float = 0.8,
                 max_normal_reps: int = 5):
        """
        Args:
            window_size: ë¹„êµí•  í† í° ìœˆë„ìš° í¬ê¸°
            threshold: ë°˜ë³µ íŒì • ìœ ì‚¬ë„ ì„ê³„ê°’ (0.0-1.0)
            max_normal_reps: ì •ìƒ ë°˜ë³µ ìµœëŒ€ íšŸìˆ˜
        """
        self.window_size = window_size
        self.threshold = threshold
        self.max_normal_reps = max_normal_reps
        self.buffer = []
        self.consecutive_reps = 0

    def add_token(self, token: str) -> bool:
        """
        í† í° ì¶”ê°€ ë° ë°˜ë³µ ê°ì§€

        Returns:
            True if repetition detected (should stop)
        """
        self.buffer.append(token)

        # ë²„í¼ê°€ ì¶©ë¶„íˆ ì°¨ë©´ ë¶„ì„
        if len(self.buffer) >= self.window_size * 2:
            recent = ''.join(self.buffer[-self.window_size:])
            previous = ''.join(self.buffer[-self.window_size*2:-self.window_size])

            # ìœ ì‚¬ë„ ê³„ì‚°
            similarity = self._calculate_similarity(recent, previous)

            if similarity > self.threshold:
                self.consecutive_reps += 1

                # ì—°ì† ë°˜ë³µì´ í—ˆìš© íšŸìˆ˜ ì´ˆê³¼
                if self.consecutive_reps > self.max_normal_reps:
                    return True
            else:
                # ë°˜ë³µì´ ëŠê¸°ë©´ ì¹´ìš´í„° ë¦¬ì…‹
                self.consecutive_reps = 0

            # ë²„í¼ í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
            if len(self.buffer) > self.window_size * 3:
                self.buffer = self.buffer[-self.window_size*2:]

        return False

    def _calculate_similarity(self, s1: str, s2: str) -> float:
        """ë‘ ë¬¸ìì—´ì˜ ìœ ì‚¬ë„ ê³„ì‚°"""
        if s1 == s2:
            return 1.0
        # SequenceMatcherë¥¼ ì‚¬ìš©í•œ ìœ ì‚¬ë„ ê³„ì‚°
        return SequenceMatcher(None, s1, s2).ratio()

    def reset(self):
        """ë²„í¼ì™€ ì¹´ìš´í„° ë¦¬ì…‹"""
        self.buffer = []
        self.consecutive_reps = 0


@dataclass
class PDFProgress:
    """PDF ì²˜ë¦¬ ì§„í–‰ ìƒí™©"""
    pdf_path: str
    total_pages: int
    completed_pages: set[int] = field(default_factory=set)
    failed_pages: dict[int, str] = field(default_factory=dict)  # {í˜ì´ì§€ë²ˆí˜¸: ì—ëŸ¬ë©”ì‹œì§€}
    skipped_pages: set[int] = field(default_factory=set)
    last_update: datetime = field(default_factory=datetime.now)

    def save(self, progress_file: Path):
        """ì§„í–‰ ìƒí™© ì €ì¥"""
        try:
            with open(progress_file, 'wb') as f:
                pickle.dump(self, f)
        except Exception as e:
            print(f"âš ï¸ ì§„í–‰ ìƒí™© ì €ì¥ ì‹¤íŒ¨: {e}")

    @classmethod
    def load(cls, progress_file: Path) -> Optional['PDFProgress']:
        """ì§„í–‰ ìƒí™© ë¡œë“œ"""
        if not progress_file.exists():
            return None
        try:
            with open(progress_file, 'rb') as f:
                return pickle.load(f)
        except Exception as e:
            print(f"âš ï¸ ì§„í–‰ ìƒí™© ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def get_pending_pages(self) -> list[int]:
        """ì•„ì§ ì²˜ë¦¬ë˜ì§€ ì•Šì€ í˜ì´ì§€ ëª©ë¡"""
        all_pages = set(range(1, self.total_pages + 1))
        pending = all_pages - self.completed_pages - self.skipped_pages
        return sorted(pending)

    def is_complete(self) -> bool:
        """ëª¨ë“  í˜ì´ì§€ ì²˜ë¦¬ ì™„ë£Œ ì—¬ë¶€"""
        return len(self.completed_pages) + len(self.skipped_pages) >= self.total_pages


def check_server_health() -> bool:
    """ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    try:
        response = httpx.get(HEALTH_ENDPOINT, timeout=5)
        if response.status_code == 200:
            print("âœ… ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return True
    except httpx.ConnectError:
        print("âŒ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        print("   ./start_server.shë¥¼ ì‹¤í–‰í•˜ì—¬ ì„œë²„ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”")
    except Exception as e:
        print(f"âŒ ì„œë²„ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    return False


def image_to_base64(image_path: Path) -> str:
    """ì´ë¯¸ì§€ íŒŒì¼ì„ base64 ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def pdf_to_images(pdf_path: Path) -> list[Image.Image]:
    """PDF íŒŒì¼ì„ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        images = convert_from_path(pdf_path, dpi=200)
        print(f"ğŸ“„ PDFë¥¼ {len(images)}ê°œì˜ ì´ë¯¸ì§€ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤")
        return images
    except Exception as e:
        print(f"âŒ PDF ë³€í™˜ ì‹¤íŒ¨: {e}")
        return []


def should_save_buffer(buffer: str, mode: SaveMode) -> bool:
    """ë²„í¼ë¥¼ ì €ì¥í•´ì•¼ í•˜ëŠ”ì§€ ê²°ì •í•©ë‹ˆë‹¤."""
    if mode == SaveMode.TOKEN:
        return True  # í•­ìƒ ì¦‰ì‹œ ì €ì¥
    elif mode == SaveMode.WORD:
        return ' ' in buffer or '\n' in buffer or '\t' in buffer
    elif mode == SaveMode.SENTENCE:
        return any(p in buffer for p in ['. ', '.\n', '! ', '!\n', '? ', '?\n', 'ã€‚', 'ï¼›'])
    elif mode == SaveMode.PARAGRAPH:
        return '\n\n' in buffer or buffer.count('\n') >= 2
    elif mode == SaveMode.LINE:
        return '\n' in buffer
    return False


def perform_ocr(
    image_base64: str,
    prompt: str = "Perform OCR on this image and extract all visible text accurately. Preserve the original structure, formatting, and layout as much as possible. Include headings, paragraphs, lists, tables, equations, and any other textual content. For figures, diagrams, charts, or images, describe their position (e.g., 'top-left', 'center', 'bottom-right'), their relationship to surrounding text, and provide a brief description of what they depict. Use markdown format with placeholders like '![Figure X: description](position)' for visual elements. Maintain the spatial hierarchy and reading order of the document.",
    output_file: Optional[Path] = None,
    stream: bool = True,
    save_mode: SaveMode = SaveMode.TOKEN,
    quiet: bool = False,
    show_stats: bool = False,
    page_timeout: Optional[float] = None,
    max_page_tokens: Optional[int] = None
) -> str:
    """ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""

    # ìš”ì²­ ë°ì´í„° êµ¬ì„±
    request_data = {
        "model": MODEL_NAME,
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_base64}"
                        }
                    }
                ]
            }
        ],
        "temperature": 0.1,
        "max_tokens": 4096,
        "stream": stream
    }

    # í†µê³„ ë³€ìˆ˜
    stats = {
        "tokens": 0,
        "saves": 0,
        "start_time": time.time(),
        "first_token_time": None
    }

    if not stream:
        # ë¹„ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
        try:
            response = httpx.post(API_ENDPOINT, json=request_data, timeout=60)
            if response.status_code == 200:
                result = response.json()
                if "choices" in result and len(result["choices"]) > 0:
                    text = result["choices"][0]["message"]["content"]

                    if not quiet:
                        print(text)

                    if output_file:
                        with open(output_file, "a", encoding="utf-8") as f:
                            f.write(text)

                    return text
            else:
                if not quiet:
                    print(f"âŒ API ì˜¤ë¥˜: {response.status_code}")
                raise APIError(f"API error: {response.status_code}")
        except APIError:
            raise
        except Exception as e:
            print(f"âŒ OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            raise APIError(f"OCR processing error: {e}")

    # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
    file_handle = None
    if output_file:
        # Python 3ì—ì„œëŠ” í…ìŠ¤íŠ¸ ëª¨ë“œì—ì„œ unbuffered(0)ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ
        # ìµœì†Œ line buffered(1) ì‚¬ìš©í•˜ê³ , TOKEN ëª¨ë“œì—ì„œëŠ” flush()ì™€ fsync()ë¡œ ì¦‰ì‹œ ì €ì¥
        file_handle = open(output_file, "a", encoding="utf-8", buffering=1)

    # ë°˜ë³µ ê°ì§€ê¸° ì´ˆê¸°í™”
    repetition_detector = RepetitionDetector()

    total_text = ""
    try:
        buffer = ""
        # íƒ€ì„ì•„ì›ƒ ì„¤ì • (ê¸°ë³¸ê°’: 120ì´ˆ, í˜ì´ì§€ íƒ€ì„ì•„ì›ƒì´ ìˆìœ¼ë©´ ê·¸ê²ƒ ì‚¬ìš©)
        timeout = page_timeout if page_timeout else 120
        with httpx.Client(timeout=timeout) as client:
            with client.stream("POST", API_ENDPOINT, json=request_data) as response:
                if response.status_code != 200:
                    if not quiet:
                        print(f"âŒ API ì˜¤ë¥˜: {response.status_code}")
                    raise APIError(f"API error: {response.status_code}")

                for line in response.iter_lines():
                    if line.startswith("data: "):
                        data = line[6:]

                        if data == "[DONE]":
                            # ë§ˆì§€ë§‰ ë²„í¼ ì²˜ë¦¬
                            if buffer and file_handle:
                                file_handle.write(buffer)
                                file_handle.flush()
                                stats["saves"] += 1
                            break

                        try:
                            json_data = json.loads(data)
                            if "choices" in json_data and len(json_data["choices"]) > 0:
                                delta = json_data["choices"][0].get("delta", {})
                                content = delta.get("content", "")

                                if content:
                                    # íƒ€ì„ì•„ì›ƒ ì²´í¬
                                    if page_timeout and (time.time() - stats["start_time"]) > page_timeout:
                                        if not quiet:
                                            print(f"\n\nâ±ï¸ í˜ì´ì§€ íƒ€ì„ì•„ì›ƒ ({page_timeout}ì´ˆ ì´ˆê³¼)")
                                        raise PageTimeoutError(f"Page timeout after {page_timeout} seconds")

                                    # í† í° ìˆ˜ ì²´í¬
                                    if max_page_tokens and stats["tokens"] >= max_page_tokens:
                                        if not quiet:
                                            print(f"\n\nğŸ›‘ ìµœëŒ€ í† í° ìˆ˜ ë„ë‹¬ ({max_page_tokens})")
                                        raise TokenLimitError(f"Token limit reached: {max_page_tokens}")

                                    # ë°˜ë³µ ê°ì§€
                                    if repetition_detector.add_token(content):
                                        if not quiet:
                                            print(f"\n\nâš ï¸ ë°˜ë³µ íŒ¨í„´ ê°ì§€! ({repetition_detector.consecutive_reps}íšŒ ì—°ì† {int(repetition_detector.threshold*100)}% ìœ ì‚¬)")
                                        raise RepetitionError(f"Repetition pattern detected after {repetition_detector.consecutive_reps} consecutive repetitions")

                                    # ì²« í† í° ì‹œê°„ ê¸°ë¡
                                    if stats["first_token_time"] is None:
                                        stats["first_token_time"] = time.time()

                                    stats["tokens"] += 1
                                    total_text += content

                                    # í™”ë©´ ì¶œë ¥
                                    if not quiet:
                                        print(content, end="", flush=True)

                                    # ì €ì¥ ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬
                                    if save_mode == SaveMode.TOKEN:
                                        # ì¦‰ì‹œ ì €ì¥
                                        if file_handle:
                                            file_handle.write(content)
                                            file_handle.flush()
                                            os.fsync(file_handle.fileno())
                                            stats["saves"] += 1
                                    else:
                                        # ë²„í¼ì— ì¶”ê°€í•˜ê³  ì¡°ê±´ í™•ì¸
                                        buffer += content
                                        if should_save_buffer(buffer, save_mode):
                                            if file_handle:
                                                file_handle.write(buffer)
                                                file_handle.flush()
                                                stats["saves"] += 1
                                            buffer = ""

                        except json.JSONDecodeError:
                            continue

    except (RepetitionError, PageTimeoutError, TokenLimitError, APIError) as e:
        # ìš°ë¦¬ê°€ ì •ì˜í•œ ì˜ˆì™¸ë“¤ì€ ê·¸ëŒ€ë¡œ ì „íŒŒ
        if not quiet:
            print(f"\nğŸ›‘ ì²˜ë¦¬ ì¤‘ë‹¨: {e}")
        raise
    except httpx.TimeoutException:
        if not quiet:
            print("\nâ±ï¸ ìš”ì²­ ì‹œê°„ ì´ˆê³¼")
        raise APIError("Request timeout")
    except Exception as e:
        if not quiet:
            print(f"\nâŒ OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        raise APIError(f"Unexpected error: {e}")
    finally:
        if file_handle:
            file_handle.flush()
            file_handle.close()

        # í†µê³„ ì¶œë ¥
        if show_stats and stats["first_token_time"]:
            elapsed = time.time() - stats["start_time"]
            time_to_first = stats["first_token_time"] - stats["start_time"]

            print(f"\n\nğŸ“Š ìŠ¤íŠ¸ë¦¬ë° í†µê³„:")
            print(f"   ì €ì¥ ëª¨ë“œ: {save_mode.value}")
            print(f"   ì´ í† í° ìˆ˜: {stats['tokens']}")
            print(f"   íŒŒì¼ ì €ì¥ íšŸìˆ˜: {stats['saves']}")
            print(f"   ì²« í† í°ê¹Œì§€: {time_to_first:.2f}ì´ˆ")
            print(f"   ì „ì²´ ì‹œê°„: {elapsed:.2f}ì´ˆ")
            print(f"   í† í°/ì´ˆ: {stats['tokens']/elapsed:.1f}")

    return total_text


def process_image_file(
    image_path: Path,
    stream: bool = True,
    save_mode: SaveMode = SaveMode.TOKEN,
    quiet: bool = False,
    show_stats: bool = False,
    no_save: bool = False
):
    """ì´ë¯¸ì§€ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    mode_str = f"ìŠ¤íŠ¸ë¦¬ë° - {save_mode.value}" if stream else "ì¼ë°˜"
    if not quiet:
        print(f"\nğŸ–¼ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ({mode_str} ëª¨ë“œ): {image_path.name}")
        print("-" * 40)

    if not image_path.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return

    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    output_path = None
    if not no_save:
        if stream and save_mode != SaveMode.TOKEN:
            output_path = image_path.with_suffix(f".{save_mode.value}.md")
        else:
            output_path = image_path.with_suffix(".md")

        # íŒŒì¼ ì´ˆê¸°í™”
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(f"# OCR ê²°ê³¼: {image_path.name}\n\n")
            f.write(f"**ì²˜ë¦¬ ë°©ì‹**: {mode_str}\n\n")
            f.write("---\n\n")

        if not quiet:
            print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_path}")

    if not quiet:
        print(f"ğŸ” OCR ì²˜ë¦¬ ì¤‘...")
        if stream:
            print("=" * 50)

    # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜
    start_time = time.time()
    image_base64 = image_to_base64(image_path)

    # OCR ìˆ˜í–‰
    try:
        extracted_text = perform_ocr(
            image_base64,
            output_file=output_path,
            stream=stream,
            save_mode=save_mode,
            quiet=quiet,
            show_stats=show_stats
        )
    except (RepetitionError, PageTimeoutError, TokenLimitError) as e:
        if not quiet:
            print(f"\nâš ï¸ ì²˜ë¦¬ ì¤‘ë‹¨: {e}")
        # ë¶€ë¶„ ê²°ê³¼ë¼ë„ ì €ì¥
        if output_path:
            with open(output_path, "a", encoding="utf-8") as f:
                f.write(f"\n\n*[ì²˜ë¦¬ ì¤‘ë‹¨: {e}]*\n")
        extracted_text = None
    except APIError as e:
        if not quiet:
            print(f"\nâŒ API ì˜¤ë¥˜: {e}")
        if output_path:
            with open(output_path, "a", encoding="utf-8") as f:
                f.write(f"\n\n*[API ì˜¤ë¥˜: {e}]*\n")
        extracted_text = None

    elapsed_time = time.time() - start_time

    if stream and not quiet:
        print("\n" + "=" * 50)

    # ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€
    if output_path:
        with open(output_path, "a", encoding="utf-8") as f:
            f.write(f"\n\n---\n\n**ì²˜ë¦¬ ì‹œê°„**: {elapsed_time:.2f}ì´ˆ\n")

    if extracted_text:
        if not quiet:
            print(f"\nâœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ ({elapsed_time:.2f}ì´ˆ)")
            if output_path:
                print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_path}")
    else:
        if not quiet:
            print(f"\nâš ï¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ì¤‘ë‹¨ ({elapsed_time:.2f}ì´ˆ)")
            if output_path:
                print(f"ğŸ’¾ ë¶€ë¶„ ê²°ê³¼ ì €ì¥: {output_path}")


def process_pdf_file(
    pdf_path: Path,
    stream: bool = True,
    save_mode: SaveMode = SaveMode.TOKEN,
    quiet: bool = False,
    show_stats: bool = False,
    no_save: bool = False,
    resume: bool = False,
    start_page: Optional[int] = None,
    skip_errors: bool = False,
    max_retries: int = 2,
    page_timeout: Optional[float] = 120.0,
    max_page_tokens: Optional[int] = 8000
):
    """PDF íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    mode_str = f"ìŠ¤íŠ¸ë¦¬ë° - {save_mode.value}" if stream else "ì¼ë°˜"
    if not quiet:
        print(f"\nğŸ“„ PDF ì²˜ë¦¬ ({mode_str} ëª¨ë“œ): {pdf_path.name}")
        print("-" * 40)

    if not pdf_path.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return

    # ì§„í–‰ ìƒí™© íŒŒì¼ ê²½ë¡œ
    progress_file = pdf_path.with_suffix('.progress')

    # ì§„í–‰ ìƒí™© ë¡œë“œ ë˜ëŠ” ì´ˆê¸°í™”
    progress = None
    if resume:
        progress = PDFProgress.load(progress_file)
        if progress and progress.pdf_path == str(pdf_path):
            if not quiet:
                print(f"ğŸ“‚ ì´ì „ ì§„í–‰ ìƒí™© ë³µì›: {len(progress.completed_pages)}/{progress.total_pages} í˜ì´ì§€ ì™„ë£Œ")
        else:
            if not quiet:
                print("âš ï¸ ì´ì „ ì§„í–‰ ìƒí™©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
            progress = None

    # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    images = pdf_to_images(pdf_path)
    if not images:
        return

    # ì§„í–‰ ìƒí™© ì´ˆê¸°í™” (í•„ìš” ì‹œ)
    if progress is None:
        progress = PDFProgress(
            pdf_path=str(pdf_path),
            total_pages=len(images)
        )

    # ì²˜ë¦¬í•  í˜ì´ì§€ ê²°ì •
    if start_page:
        pages_to_process = list(range(start_page, len(images) + 1))
    else:
        pages_to_process = progress.get_pending_pages()
        if not pages_to_process and not quiet:
            print("âœ… ëª¨ë“  í˜ì´ì§€ê°€ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return

    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    output_path = None
    if not no_save:
        if stream and save_mode != SaveMode.TOKEN:
            output_path = pdf_path.with_suffix(f".{save_mode.value}.md")
        else:
            output_path = pdf_path.with_suffix(".md")

        # íŒŒì¼ ì´ˆê¸°í™”
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(f"# OCR ê²°ê³¼: {pdf_path.name}\n\n")
            f.write(f"**ì´ í˜ì´ì§€ ìˆ˜**: {len(images)}í˜ì´ì§€\n")
            f.write(f"**ì²˜ë¦¬ ë°©ì‹**: {mode_str}\n\n")
            f.write("---\n\n")

        if not quiet:
            print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_path}")

    total_start_time = time.time()
    success_count = 0

    # ê° í˜ì´ì§€ ì²˜ë¦¬
    for page_num in pages_to_process:
        # ì´ë¯¸ ì™„ë£Œëœ í˜ì´ì§€ëŠ” ê±´ë„ˆë›°ê¸°
        if page_num in progress.completed_pages:
            if not quiet:
                print(f"\nâœ… í˜ì´ì§€ {page_num} ì´ë¯¸ ì™„ë£Œë¨ (ê±´ë„ˆëœ€)")
            success_count += 1
            continue

        if not quiet:
            print(f"\nğŸ“– í˜ì´ì§€ {page_num}/{len(images)} ì²˜ë¦¬ ì¤‘...")
            if stream:
                print("-" * 40)

        # í˜ì´ì§€ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
        image = images[page_num - 1]

        retry_count = 0
        page_success = False

        while retry_count < max_retries and not page_success:
            try:
                if retry_count > 0 and not quiet:
                    print(f"ğŸ”„ í˜ì´ì§€ {page_num} ì¬ì‹œë„ ({retry_count}/{max_retries})")

                # PIL Imageë¥¼ base64ë¡œ ë³€í™˜
                buffer = io.BytesIO()
                image.save(buffer, format="JPEG", quality=95)
                image_base64 = base64.b64encode(buffer.getvalue()).decode()

                # í˜ì´ì§€ í—¤ë” ì¶”ê°€ (ì²« ì‹œë„ì¼ ë•Œë§Œ)
                if output_path and retry_count == 0:
                    with open(output_path, "a", encoding="utf-8") as f:
                        f.write(f"## í˜ì´ì§€ {page_num}\n\n")

                # OCR ìˆ˜í–‰
                extracted_text = perform_ocr(
                    image_base64,
                    f"Perform OCR on page {page_num} of this document. Extract all visible text accurately while preserving the original structure, formatting, and layout. Include headings, paragraphs, lists, tables, equations, citations, and any other textual content. For figures, diagrams, charts, or images, describe their position (e.g., 'top-left', 'center', 'bottom-right'), their relationship to surrounding text, and provide a brief description of what they depict. Use markdown format with placeholders like '![Figure X: description](position)' for visual elements. Maintain the spatial hierarchy and reading order of the document.",
                    output_file=output_path,
                    stream=stream,
                    save_mode=save_mode,
                    quiet=quiet,
                    show_stats=False,  # í˜ì´ì§€ë³„ í†µê³„ëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŒ
                    page_timeout=page_timeout,
                    max_page_tokens=max_page_tokens
                )

                if extracted_text:
                    progress.completed_pages.add(page_num)
                    page_success = True
                    success_count += 1
                    if not quiet:
                        print(f"\nâœ… í˜ì´ì§€ {page_num} ì™„ë£Œ")

            except APIError as e:
                error_msg = str(e)
                retry_count += 1
                if not quiet:
                    print(f"\nâŒ API ì˜¤ë¥˜: {error_msg}")

                if retry_count >= max_retries:
                    progress.failed_pages[page_num] = error_msg
                    if skip_errors:
                        progress.skipped_pages.add(page_num)
                        if output_path:
                            with open(output_path, "a", encoding="utf-8") as f:
                                f.write(f"*[API ì˜¤ë¥˜: {error_msg}]*\n")
                        if not quiet:
                            print(f"â­ï¸ í˜ì´ì§€ {page_num} ê±´ë„ˆëœ€")
                        break
                    else:
                        if not quiet:
                            print(f"\nâŒ í˜ì´ì§€ {page_num} ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                        progress.save(progress_file)
                        return

            except (RepetitionError, PageTimeoutError, TokenLimitError) as e:
                error_msg = str(e)
                if not quiet:
                    print(f"\nâš ï¸ í˜ì´ì§€ {page_num}: {error_msg}")

                if skip_errors:
                    progress.skipped_pages.add(page_num)
                    progress.failed_pages[page_num] = error_msg
                    if output_path:
                        with open(output_path, "a", encoding="utf-8") as f:
                            f.write(f"*[{error_msg}]*\n")
                    if not quiet:
                        print(f"â­ï¸ í˜ì´ì§€ {page_num} ê±´ë„ˆëœ€")
                    break
                else:
                    retry_count += 1
                    if retry_count >= max_retries:
                        progress.failed_pages[page_num] = error_msg
                        if not quiet:
                            print(f"\nâŒ í˜ì´ì§€ {page_num} ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                        # skip_errorsê°€ Falseë©´ ì—¬ê¸°ì„œ ì „ì²´ ì¤‘ë‹¨
                        progress.save(progress_file)
                        return

            except Exception as e:
                error_msg = str(e)
                print(f"\nâŒ í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
                retry_count += 1
                progress.failed_pages[page_num] = error_msg
                if retry_count >= max_retries:
                    if output_path:
                        with open(output_path, "a", encoding="utf-8") as f:
                            f.write(f"*[ì²˜ë¦¬ ì˜¤ë¥˜: {error_msg}]*\n")
                    if skip_errors:
                        progress.skipped_pages.add(page_num)
                        break
                    else:
                        progress.save(progress_file)
                        return

        # í˜ì´ì§€ êµ¬ë¶„ì ì¶”ê°€
        if output_path and page_num < len(images):
            with open(output_path, "a", encoding="utf-8") as f:
                f.write("\n\n---\n\n")

        # ì§„í–‰ ìƒí™© ì €ì¥ (í˜ì´ì§€ë§ˆë‹¤)
        progress.last_update = datetime.now()
        progress.save(progress_file)

    total_elapsed = time.time() - total_start_time

    # ë§ˆì§€ë§‰ì— ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€
    if output_path:
        with open(output_path, "a", encoding="utf-8") as f:
            f.write(f"\n---\n\n**ì „ì²´ ì²˜ë¦¬ ì‹œê°„**: {total_elapsed:.2f}ì´ˆ\n")

    # ì™„ë£Œ ì‹œ ì§„í–‰ ìƒí™© íŒŒì¼ ì²˜ë¦¬
    if progress.is_complete():
        progress_file.unlink(missing_ok=True)
        if not quiet:
            print(f"ğŸ—‘ï¸ ì§„í–‰ ìƒí™© íŒŒì¼ ì‚­ì œ (ëª¨ë“  í˜ì´ì§€ ì™„ë£Œ)")

    if not quiet:
        print(f"\nâœ… ì „ì²´ PDF ì²˜ë¦¬ ì™„ë£Œ ({total_elapsed:.2f}ì´ˆ)")
        print(f"   ì„±ê³µ: {success_count}/{len(images)} í˜ì´ì§€")
        if len(progress.skipped_pages) > 0:
            print(f"   ê±´ë„ˆëœ€: {len(progress.skipped_pages)} í˜ì´ì§€")
        if len(progress.failed_pages) > 0:
            print(f"   ì‹¤íŒ¨: {len(progress.failed_pages)} í˜ì´ì§€")
        if output_path:
            print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_path}")

    if show_stats:
        print(f"\nğŸ“Š ì²˜ë¦¬ í†µê³„:")
        print(f"   ì´ í˜ì´ì§€: {len(images)}")
        print(f"   ì„±ê³µí•œ í˜ì´ì§€: {success_count}")
        print(f"   í‰ê·  í˜ì´ì§€ ì²˜ë¦¬ ì‹œê°„: {total_elapsed/len(images):.2f}ì´ˆ")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    global SERVER_URL, API_ENDPOINT, HEALTH_ENDPOINT

    parser = argparse.ArgumentParser(
        description="LightOnOCR - llama.cpp ê¸°ë°˜ OCR í´ë¼ì´ì–¸íŠ¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì œ:
  ê¸°ë³¸ ì‚¬ìš© (ìŠ¤íŠ¸ë¦¬ë°):
    python ocr.py image.png
    python ocr.py document.pdf

  ë¹„ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ:
    python ocr.py --no-stream image.png

  ì €ì¥ ëª¨ë“œ ë³€ê²½:
    python ocr.py --save-mode sentence document.jpg
    python ocr.py -m paragraph long_document.pdf

  ì¡°ìš©í•œ ëª¨ë“œ:
    python ocr.py --quiet image.png

  í†µê³„ í‘œì‹œ:
    python ocr.py --stats document.pdf

  íŒŒì¼ ì €ì¥ ì•ˆ í•¨:
    python ocr.py --no-save image.png
        """
    )

    parser.add_argument('file', type=str, nargs='?',
                       help='ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œ (ì´ë¯¸ì§€ ë˜ëŠ” PDF)')

    parser.add_argument('--no-stream', action='store_true',
                       help='ë¹„ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì‚¬ìš© (ê¸°ë³¸: ìŠ¤íŠ¸ë¦¬ë°)')

    parser.add_argument('-m', '--save-mode', type=str,
                       choices=[m.value for m in SaveMode],
                       default=SaveMode.TOKEN.value,
                       help=f'íŒŒì¼ ì €ì¥ ëª¨ë“œ (ê¸°ë³¸: {SaveMode.TOKEN.value})')

    parser.add_argument('-q', '--quiet', action='store_true',
                       help='ì¡°ìš©í•œ ëª¨ë“œ (í…ìŠ¤íŠ¸ ì¶œë ¥ ì•ˆ í•¨)')

    parser.add_argument('--stats', action='store_true',
                       help='ì²˜ë¦¬ í†µê³„ í‘œì‹œ')

    parser.add_argument('--no-save', action='store_true',
                       help='íŒŒì¼ë¡œ ì €ì¥í•˜ì§€ ì•ŠìŒ')

    parser.add_argument('--server', type=str, default=SERVER_URL,
                       help=f'ì„œë²„ URL (ê¸°ë³¸: {SERVER_URL})')

    # ìƒˆë¡œìš´ ì¸ìë“¤ ì¶”ê°€
    parser.add_argument('--resume', action='store_true',
                       help='ì¤‘ë‹¨ëœ ìœ„ì¹˜ë¶€í„° ì¬ì‹œì‘ (.progress íŒŒì¼ ì‚¬ìš©)')

    parser.add_argument('--start-page', type=int, metavar='N',
                       help='íŠ¹ì • í˜ì´ì§€ë¶€í„° ì‹œì‘ (1ë¶€í„° ì‹œì‘)')

    parser.add_argument('--skip-errors', action='store_true',
                       help='ë¬¸ì œ í˜ì´ì§€ ê±´ë„ˆë›°ê³  ê³„ì† ì§„í–‰')

    parser.add_argument('--max-retries', type=int, default=2, metavar='N',
                       help='í˜ì´ì§€ë‹¹ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸: 2)')

    parser.add_argument('--page-timeout', type=float, default=120.0, metavar='SECONDS',
                       help='í˜ì´ì§€ë‹¹ ìµœëŒ€ ì²˜ë¦¬ ì‹œê°„ (ì´ˆ, ê¸°ë³¸: 120)')

    parser.add_argument('--max-page-tokens', type=int, default=8000, metavar='N',
                       help='í˜ì´ì§€ë‹¹ ìµœëŒ€ í† í° ìˆ˜ (ê¸°ë³¸: 8000)')

    # ì„¤ì • íŒŒì¼ ê´€ë ¨ ì¸ì
    parser.add_argument('-c', '--config', type=str, metavar='FILE',
                       help='YAML ì„¤ì • íŒŒì¼ ê²½ë¡œ')

    parser.add_argument('--create-config', type=str, metavar='FILE',
                       help='ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„±')

    parser.add_argument('--no-config', action='store_true',
                       help='ì„¤ì • íŒŒì¼ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ')

    args = parser.parse_args()

    # ì„¤ì • íŒŒì¼ ìƒì„± ìš”ì²­ ì²˜ë¦¬
    if args.create_config:
        config_path = Path(args.create_config)
        if create_default_config(config_path):
            print(f"ğŸ‰ ì„¤ì • íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {config_path}")
            print("   í•„ìš”ì— ë”°ë¼ íŒŒì¼ì„ ìˆ˜ì •í•œ í›„ ì‚¬ìš©í•˜ì„¸ìš”.")
        sys.exit(0)

    # ì„¤ì • íŒŒì¼ ë¡œë“œ ë° ë³‘í•©
    if not args.no_config:
        if args.config:
            # ëª…ì‹œì ìœ¼ë¡œ ì§€ì •ëœ ì„¤ì • íŒŒì¼
            config_path = Path(args.config)
            config = load_config_file(config_path)
        else:
            # ê¸°ë³¸ ìœ„ì¹˜ì—ì„œ ì„¤ì • íŒŒì¼ ì°¾ê¸°
            config = load_config_file()

        if config:
            args = merge_config_with_args(config, args)

    # ì „ì—­ ì„œë²„ URL ì—…ë°ì´íŠ¸
    if args.server != SERVER_URL:
        SERVER_URL = args.server
        API_ENDPOINT = f"{SERVER_URL}/v1/chat/completions"
        HEALTH_ENDPOINT = f"{SERVER_URL}/health"

    print("=" * 50)
    print("   LightOnOCR - í†µí•© OCR í´ë¼ì´ì–¸íŠ¸")
    print("=" * 50)

    # ì„œë²„ ìƒíƒœ í™•ì¸
    if not check_server_health():
        sys.exit(1)

    # íŒŒì¼ ê²½ë¡œ í™•ì¸
    if not args.file:
        # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì°¾ê¸°
        test_files = [
            Path("data/test.pdf"),
            Path("data/test_images/sample.png"),
            Path("data/test_images/sample.jpg")
        ]

        file_path = None
        for f in test_files:
            if f.exists():
                file_path = f
                print(f"\ní…ŒìŠ¤íŠ¸ íŒŒì¼ ì‚¬ìš©: {file_path}")
                break

        if not file_path:
            print("\nâŒ íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•˜ê±°ë‚˜ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”")
            parser.print_help()
            sys.exit(1)
    else:
        file_path = Path(args.file)

    # SaveMode ë³€í™˜
    save_mode = SaveMode(args.save_mode)

    # ì„¤ì • í‘œì‹œ
    if not args.quiet:
        print(f"\nâš™ï¸ ì„¤ì •:")
        print(f"   ìŠ¤íŠ¸ë¦¬ë°: {'ë¹„í™œì„±í™”' if args.no_stream else 'í™œì„±í™”'}")
        if not args.no_stream:
            print(f"   ì €ì¥ ëª¨ë“œ: {save_mode.value}")
        print(f"   íŒŒì¼ ì €ì¥: {'ë¹„í™œì„±í™”' if args.no_save else 'í™œì„±í™”'}")
        print(f"   í†µê³„ í‘œì‹œ: {'í™œì„±í™”' if args.stats else 'ë¹„í™œì„±í™”'}")

    # íŒŒì¼ ì²˜ë¦¬
    if file_path.suffix.lower() == ".pdf":
        process_pdf_file(
            file_path,
            stream=not args.no_stream,
            save_mode=save_mode,
            quiet=args.quiet,
            show_stats=args.stats,
            no_save=args.no_save,
            resume=args.resume,
            start_page=args.start_page,
            skip_errors=args.skip_errors,
            max_retries=args.max_retries,
            page_timeout=args.page_timeout,
            max_page_tokens=args.max_page_tokens
        )
    elif file_path.suffix.lower() in [".png", ".jpg", ".jpeg", ".bmp", ".gif", ".tiff"]:
        process_image_file(
            file_path,
            stream=not args.no_stream,
            save_mode=save_mode,
            quiet=args.quiet,
            show_stats=args.stats,
            no_save=args.no_save
        )
    else:
        print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_path.suffix}")
        print("   ì§€ì› í˜•ì‹: PDF, PNG, JPG, JPEG, BMP, GIF, TIFF")
        sys.exit(1)

    if not args.quiet:
        print("\nâœ… OCR ì²˜ë¦¬ ì™„ë£Œ!")


if __name__ == "__main__":
    main()